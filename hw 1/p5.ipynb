{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment represents my own work. I did not work on this assignment with others. All coding was done by myself.\n",
    "\n",
    "I understand that if I struggle with this assignment that I will reevaluate whether this is the correct class for me to take. I understand that the homework only gets harder.\n",
    "\n",
    "# CS 671: Homework 1\n",
    "### Alex Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from chefboost import Chefboost as chef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General Data Helper Functions\n",
    "\n",
    "# Returns train and test data\n",
    "def getData():\n",
    "    return pd.read_csv(\"carseats_train.csv\"), pd.read_csv(\"carseats_test.csv\")\n",
    "\n",
    "# Separates the feature vector from the label associated with it\n",
    "def splitXY(data):\n",
    "    return data.iloc[:, 1:].to_numpy(), data.iloc[:, 0].to_numpy()\n",
    "\n",
    "# Change categorical data to numerical\n",
    "def cleanX(data):\n",
    "    old, new = [\"Bad\", \"Medium\", \"Good\", \"No\", \"Yes\"], [0, 1, 2, 0, 1]\n",
    "    for i in range(len(old)):\n",
    "        data[data == old[i]] = new[i]\n",
    "    return data\n",
    "\n",
    "# Renames and relocates the label column; changes numerical to categorical\n",
    "def chefPrep(data):\n",
    "    data = data.rename(columns={\"Sales\": \"Decision\"})\n",
    "    dec = data.pop(\"Decision\")\n",
    "    data.insert(len(data.columns), \"Decision\", dec)\n",
    "\n",
    "    data.loc[data[\"Decision\"] == 0, \"Decision\"] = \"No\"\n",
    "    data.loc[data[\"Decision\"] == 1, \"Decision\"] = \"Yes\"\n",
    "    return data\n",
    "\n",
    "\n",
    "### For CV\n",
    "# Split data into K folds as np array for CV\n",
    "def kFolds(data_X, data_Y, K=5):\n",
    "    folds_X, folds_Y = [], []\n",
    "    bucket = len(data_X) // K\n",
    "    start, end = 0, bucket\n",
    "    for i in range(K):\n",
    "        if i+1 == K:\n",
    "            folds_X.append(data_X[start:])\n",
    "            folds_Y.append(data_Y[start:])\n",
    "        else:\n",
    "            folds_X.append(data_X[start: end])\n",
    "            folds_Y.append(data_Y[start: end])\n",
    "        start += bucket\n",
    "        end += bucket\n",
    "    return folds_X, folds_Y\n",
    "\n",
    "# Prepare train / valid pairs for CV\n",
    "def cvSplit(data_X, data_Y, K=5):\n",
    "    validX, validY, trainX, trainY = [], [], [], []\n",
    "    folds = list(range(K))\n",
    "    for i in range(K):\n",
    "        vX, vY, tX, tY = [], [], [], []\n",
    "        temp = folds.copy()\n",
    "        temp.remove(i)\n",
    "        vX, vY = data_X[i], data_Y[i]\n",
    "        for j in temp:\n",
    "            if len(tX) == 0:\n",
    "                tX, tY = data_X[j], data_Y[j]\n",
    "            else:\n",
    "                tX = np.concatenate((data_X[j], tX))\n",
    "                tY = np.concatenate((data_Y[j], tY))\n",
    "        validX.append(vX)\n",
    "        validY.append(vY)\n",
    "        trainX.append(tX)\n",
    "        trainY.append(tY)\n",
    "    return validX, validY, trainX, trainY\n",
    "\n",
    "# Split data into K folds as pd dataframe for CV\n",
    "def kFoldsChef(data, K):\n",
    "    folds = []\n",
    "    bucket = len(data) // K\n",
    "    start, end = 0, bucket\n",
    "    for i in range(K):\n",
    "        if i+1 == K:\n",
    "            folds.append(data.iloc[start:])\n",
    "        else:\n",
    "            folds.append(data.iloc[start: end])\n",
    "        start += bucket\n",
    "        end += bucket\n",
    "    return folds\n",
    "\n",
    "# Prepare train / valid pairs for CV \n",
    "def cvSplitChef(data, K):\n",
    "    valid, train = [], []\n",
    "    folds = list(range(K))\n",
    "    for i in range(K):\n",
    "        v, t = [], []\n",
    "        temp = folds.copy()\n",
    "        temp.remove(i)\n",
    "        v = data[i]\n",
    "        for j in temp:\n",
    "            if len(t) == 0:\n",
    "                t = data[j]\n",
    "            else:\n",
    "                t = pd.concat([data[j], t])\n",
    "        valid.append(v)\n",
    "        train.append(t)\n",
    "    return valid, train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evalutation Helper Functions\n",
    "\n",
    "# Calculate confusion matrix for 1/0\n",
    "def confusionMatrix(preds, labels):\n",
    "    confusion = [0, 0, 0, 0]    # [TP, FP, FN, TN]\n",
    "    for i in range(len(preds)):\n",
    "        p, l = preds[i], labels[i]\n",
    "        if p == 1:                              # pred pos\n",
    "            if l == 1: confusion[0] += 1        # TP\n",
    "            else: confusion[1] += 1             # FP\n",
    "        else:                                   # pred neg\n",
    "            if l == 0: confusion[3] += 1        # TN\n",
    "            else: confusion[2] += 1             # FN\n",
    "    return confusion\n",
    "\n",
    "# Calculate confusion matrix for Yes/No\n",
    "def chefConfusion(preds, labels):\n",
    "    confusion = [0, 0, 0, 0]    # [TP, FP, FN, TN]\n",
    "    for i in range(len(preds)):\n",
    "        p, l = preds[i], labels[i]\n",
    "        if p == \"Yes\":                          # pred pos\n",
    "            if l == \"Yes\": confusion[0] += 1    # TP\n",
    "            else: confusion[1] += 1             # FP\n",
    "        else:                                   # pred neg\n",
    "            if l == \"No\": confusion[3] += 1     # TN\n",
    "            else: confusion[2] += 1             # FN\n",
    "    return confusion\n",
    "\n",
    "# Precision\n",
    "def calcPrecision(c):\n",
    "    return c[0] / (c[0] + c[1])     # [TP, FP, FN, TN]\n",
    "\n",
    "# Recall\n",
    "def calcRecall(c):\n",
    "    return c[0] / (c[0] + c[2])\n",
    "\n",
    "# F1\n",
    "def calcF1(c):\n",
    "    p = calcPrecision(c)\n",
    "    r = calcRecall(c)\n",
    "    return 2 * ((p * r) / (p + r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Helper Functions\n",
    "\n",
    "# Returns euclidean distance\n",
    "def euclidDist(x, y):\n",
    "    dist = []\n",
    "    for i in range(len(x)):\n",
    "        dist.append((x[i] - y[i]) ** 2)\n",
    "    return np.sqrt(sum(dist))\n",
    "\n",
    "# Returns manhattan distance\n",
    "def manhatDist(x, y):\n",
    "    dist = []\n",
    "    for i in range(len(x)):\n",
    "        dist.append(np.abs(x[i] - y[i]))\n",
    "    return sum(dist)\n",
    "\n",
    "# Finds distance from p to all points in train, returns closest k\n",
    "def distToTrain(train_X, train_Y, p, dist_measure, k):\n",
    "    distances = []\n",
    "    for i in range(len(train_X)):\n",
    "        if dist_measure == \"euclidean\":\n",
    "            dist = euclidDist(train_X[i], p)\n",
    "        elif dist_measure == \"manhattan\":\n",
    "            dist = manhatDist(train_X[i], p)\n",
    "        distances.append((dist, train_Y[i]))\n",
    "    sorted_dist = sorted(distances)\n",
    "    return sorted_dist[:k]\n",
    "\n",
    "# Returns majority label from closest k\n",
    "def getMajority(distances):\n",
    "    g1, g2 = 0, 0\n",
    "    for d in distances:\n",
    "        if d[1] == 0: g1 += 1\n",
    "        elif d[1] == 1: g2 += 1\n",
    "    return 0 if g1 > g2 else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Helper Functions\n",
    "\n",
    "######### COMBINE INTO 1 FUNCT WITH CALL TO FUNCT TO RUN MODEL\n",
    "# Get summed f1 scores across K folds for each hyper for Decision Tree \n",
    "def rotateCV(trainX, trainY, validX, validY, hyper, K):\n",
    "    fold_vals = {}\n",
    "    for i in range(K):\n",
    "        for h in hyper:\n",
    "            cv_tree = DecisionTreeClassifier(max_depth=h, random_state=None)\n",
    "            cv_tree = cv_tree.fit(trainX[i], trainY[i])\n",
    "\n",
    "            cv_predict = cv_tree.predict(validX[i])\n",
    "            confusion_cv = confusionMatrix(cv_predict, validY[i])\n",
    "            f1_cv = calcF1(confusion_cv)\n",
    "            # print(\"{a}th fold f1 score for h value {b}: \".format(a=i, b=h), f1_cv)\n",
    "            if h not in fold_vals.keys():\n",
    "                fold_vals[h] = f1_cv\n",
    "            else:\n",
    "                fold_vals[h] += f1_cv\n",
    "    return fold_vals\n",
    "\n",
    "# Get summed f1 scores across K folds for each hyper for chefboost\n",
    "def rotateCVChef(train, valid, hyper, K):\n",
    "    fold_vals = {}\n",
    "    for i in range(K):\n",
    "        for h in hyper:\n",
    "            config = {\"algorithm\": \"CART\", \"max_depth\": h}\n",
    "            chef_cv = chef.fit(train[i], config=config)\n",
    "            chef_predict = []\n",
    "            for j in range(len(valid[i])):\n",
    "                chef_predict.append(chef.predict(chef_cv, valid[i].iloc[j]))\n",
    "            confusion = chefConfusion(chef_predict, valid[i][\"Decision\"].to_list())\n",
    "            f1_cv = calcF1(confusion)\n",
    "\n",
    "            if h not in fold_vals.keys():\n",
    "                fold_vals[h] = f1_cv\n",
    "            else:\n",
    "                fold_vals[h] += f1_cv\n",
    "    return fold_vals\n",
    "\n",
    "# Find hyperparam with best average score across K folds\n",
    "def findBestK(fold_vals, K):\n",
    "    for k in fold_vals.keys():\n",
    "        fold_vals[k] = fold_vals[k] / K\n",
    "    \n",
    "    return max(fold_vals, key=fold_vals.get)\n",
    "\n",
    "# Gets F1 score for current setting of hyperparams on valid set\n",
    "def KNNCV(train_X, train_Y, valid_X, valid_Y, k, dist_meas):\n",
    "    preds = []\n",
    "    for i in range(len(valid_X)):\n",
    "        dist = distToTrain(train_X, train_Y, valid_X[i], dist_meas, k)\n",
    "        vote = getMajority(dist)\n",
    "        preds.append(vote)\n",
    "    \n",
    "    knn_confusion = confusionMatrix(preds, valid_Y)\n",
    "    return calcF1(knn_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Main Function\n",
    "def decTree():\n",
    "    # Get and clean the data\n",
    "    train, test = getData()\n",
    "    train_X, train_Y = splitXY(train)\n",
    "    test_X, test_Y = splitXY(test)\n",
    "    train_X = cleanX(train_X)\n",
    "    test_X = cleanX(test_X)\n",
    "    \n",
    "    # Train the model\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=3, random_state=None)\n",
    "    decision_tree = decision_tree.fit(train_X, train_Y)\n",
    "\n",
    "    # Get test F1 score\n",
    "    dt_predict = decision_tree.predict(test_X)\n",
    "    confusion = confusionMatrix(dt_predict, test_Y)\n",
    "    f1 = calcF1(confusion)\n",
    "    # print(\"Decision Tree F1 Score: \", f1)\n",
    "\n",
    "    # CV\n",
    "    K, hyper = 5, [1, 2, 3, 4]\n",
    "    folds_X, folds_Y = kFolds(train_X, train_Y, K)\n",
    "    # Split into sets that are rotated\n",
    "    validX, validY, trainX, trainY = cvSplit(folds_X, folds_Y, K)\n",
    "\n",
    "    # Train over all h\n",
    "    fold_vals = rotateCV(trainX, trainY, validX, validY, hyper, K)\n",
    "    \n",
    "    # Find best h\n",
    "    max_key = findBestK(fold_vals, K)\n",
    "    print(\"Best value of hyperparmeter being tuned: \", max_key)\n",
    "        \n",
    "    # Make model with optimal hyperparam\n",
    "    optimal_tree = DecisionTreeClassifier(max_depth=max_key, random_state=None)\n",
    "    optimal_tree = optimal_tree.fit(train_X, train_Y)\n",
    "\n",
    "    # Get F1\n",
    "    optimal_predict = optimal_tree.predict(test_X)\n",
    "    confusion_optimal = confusionMatrix(optimal_predict, test_Y)\n",
    "    f1_optimal = calcF1(confusion_optimal)\n",
    "    print(\"Normal Decision Tree F1 Score: \", f1)\n",
    "    print(\"F1 score after CV tuning: \", f1_optimal)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chefboost Main Function\n",
    "def chefTime():\n",
    "    # Get and clean the data\n",
    "    train, test = getData()\n",
    "    train = chefPrep(train)\n",
    "    test = chefPrep(test)\n",
    "\n",
    "    # Train the model\n",
    "    config = {\"algorithm\": \"CART\", \"max_depth\": 5}\n",
    "    chef_model = chef.fit(train, config=config)\n",
    "    \n",
    "    # Get test F1 Score\n",
    "    chef_predict = []\n",
    "    for i in range(len(test)):\n",
    "        chef_predict.append(chef.predict(chef_model, test.iloc[i]))\n",
    "    confusion = chefConfusion(chef_predict, test[\"Decision\"].to_list())\n",
    "    f1 = calcF1(confusion)\n",
    "    # print(\"Chef F1 Score: \", f1)\n",
    "\n",
    "    # CV\n",
    "    K, hyper = 5, [1, 2, 3, 4]\n",
    "    folds = kFoldsChef(train, K)\n",
    "    # Split into sets that are rotated\n",
    "    valid_cv, train_cv = cvSplitChef(folds, K)\n",
    "    # Train over all h\n",
    "    fold_vals = rotateCVChef(train_cv, valid_cv, hyper, K)\n",
    "    \n",
    "    # Find best h\n",
    "    max_key = findBestK(fold_vals, K)\n",
    "    print(\"Best value of hyperparmeter being tuned: \", max_key)\n",
    "        \n",
    "    # Make model with optimal hyperparam\n",
    "    config = {\"algorithm\": \"CART\", \"max_depth\": max_key}\n",
    "    chef_optimal = chef.fit(train, config=config)\n",
    "\n",
    "    # Get F1\n",
    "    optimal_predict = []\n",
    "    for i in range(len(test)):\n",
    "        optimal_predict.append(chef.predict(chef_optimal, test.iloc[i]))\n",
    "    confusion_opt = chefConfusion(optimal_predict, test[\"Decision\"].to_list())\n",
    "    f1_optimal = calcF1(confusion_opt)\n",
    "    print(\"Normal Chef F1 Score: \", f1)\n",
    "    print(\"Chef F1 Score after CV Tuning: \", f1_optimal)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Main Function\n",
    "def KNN():\n",
    "    # Get and clean data\n",
    "    train, test = getData()\n",
    "    train_X, train_Y = splitXY(train)\n",
    "    test_X, test_Y = splitXY(test)\n",
    "    train_X = cleanX(train_X)\n",
    "    test_X = cleanX(test_X)\n",
    "\n",
    "    # Run KNN CV\n",
    "    dist_measures = [\"euclidean\", \"manhattan\"]\n",
    "    num_neighbors = [1, 3, 5, 7, 9]\n",
    "    K = 5\n",
    "    folds_X, folds_Y = kFolds(train_X, train_Y, K)\n",
    "    # Split into sets that are rotated\n",
    "    validX, validY, trainX, trainY = cvSplit(folds_X, folds_Y, K)\n",
    "\n",
    "    fold_vals = {}\n",
    "    for d in dist_measures:\n",
    "        for n in num_neighbors:\n",
    "            for i in range(len(trainX)):\n",
    "                cv_f1 = KNNCV(trainX[i], trainY[i], validX[i], validY[i], n, d)\n",
    "                if (d,n) not in fold_vals.keys():\n",
    "                    fold_vals[(d,n)] = cv_f1\n",
    "                else:\n",
    "                    fold_vals[(d,n)] += cv_f1\n",
    "                # print(\"Dist {d}; NumNeih {n}; Fold {i} F1 score: \".format(d=d, n=n, i=i), cv_f1)\n",
    "\n",
    "    max_key = findBestK(fold_vals, K)\n",
    "    print(\"Best distance and NN parameters: \", max_key)\n",
    "    \n",
    "    # Performance of Optimal KNN\n",
    "    preds = []\n",
    "    for i in range(len(test_X)):\n",
    "        dist = distToTrain(train_X, train_Y, test_X[i], max_key[0], max_key[1])\n",
    "        vote = getMajority(dist)\n",
    "        preds.append(vote)\n",
    "    \n",
    "    knn_confusion = confusionMatrix(preds, test_Y)\n",
    "    knn_f1 = calcF1(knn_confusion)\n",
    "    print(\"KNN F1 score after CV tuning: \", knn_f1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of hyperparmeter being tuned:  4\n",
      "Normal Decision Tree F1 Score:  0.5777777777777777\n",
      "F1 score after CV tuning:  0.6923076923076924\n"
     ]
    }
   ],
   "source": [
    "# Run Decision Tree Function\n",
    "decTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.641408920288086  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  97.16312056737588 % on  282  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[100, 3], [5, 174]]\n",
      "Precision:  97.0874 %, Recall:  95.2381 %, F1:  96.1539 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.431269884109497  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[82, 0], [3, 141]]\n",
      "Precision:  100.0 %, Recall:  96.4706 %, F1:  98.2036 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.3990559577941895  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[82, 0], [3, 141]]\n",
      "Precision:  100.0 %, Recall:  96.4706 %, F1:  98.2036 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.5331168174743652  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[82, 0], [3, 141]]\n",
      "Precision:  100.0 %, Recall:  96.4706 %, F1:  98.2036 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.4706659317016602  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[82, 0], [3, 141]]\n",
      "Precision:  100.0 %, Recall:  96.4706 %, F1:  98.2036 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.582603931427002  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.90265486725664 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[79, 2], [5, 140]]\n",
      "Precision:  97.5309 %, Recall:  94.0476 %, F1:  95.7576 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.5586268901824951  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.90265486725664 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[79, 2], [5, 140]]\n",
      "Precision:  97.5309 %, Recall:  94.0476 %, F1:  95.7576 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.6172471046447754  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.90265486725664 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[79, 2], [5, 140]]\n",
      "Precision:  97.5309 %, Recall:  94.0476 %, F1:  95.7576 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.5485520362854004  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.90265486725664 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[79, 2], [5, 140]]\n",
      "Precision:  97.5309 %, Recall:  94.0476 %, F1:  95.7576 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.577951192855835  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 1], [2, 140]]\n",
      "Precision:  98.8095 %, Recall:  97.6471 %, F1:  98.2249 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.581491231918335  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 1], [2, 140]]\n",
      "Precision:  98.8095 %, Recall:  97.6471 %, F1:  98.2249 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.581228256225586  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 1], [2, 140]]\n",
      "Precision:  98.8095 %, Recall:  97.6471 %, F1:  98.2249 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.6014139652252197  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  98.67256637168141 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 1], [2, 140]]\n",
      "Precision:  98.8095 %, Recall:  97.6471 %, F1:  98.2249 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.2408387660980225  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.01769911504425 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 5], [4, 134]]\n",
      "Precision:  94.3182 %, Recall:  95.4023 %, F1:  94.8572 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.2702221870422363  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.01769911504425 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 5], [4, 134]]\n",
      "Precision:  94.3182 %, Recall:  95.4023 %, F1:  94.8572 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.2755241394042969  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.01769911504425 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 5], [4, 134]]\n",
      "Precision:  94.3182 %, Recall:  95.4023 %, F1:  94.8572 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.27650785446167  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  96.01769911504425 % on  226  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[83, 5], [4, 134]]\n",
      "Precision:  94.3182 %, Recall:  95.4023 %, F1:  94.8572 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.4284229278564453  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  99.55357142857143 % on  224  instances\n",
      "Labels:  ['No' 'Yes']\n",
      "Confusion matrix:  [[145, 1], [0, 78]]\n",
      "Precision:  99.3151 %, Recall:  100.0 %, F1:  99.6564 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.4346230030059814  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  99.55357142857143 % on  224  instances\n",
      "Labels:  ['No' 'Yes']\n",
      "Confusion matrix:  [[145, 1], [0, 78]]\n",
      "Precision:  99.3151 %, Recall:  100.0 %, F1:  99.6564 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.4274659156799316  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  99.55357142857143 % on  224  instances\n",
      "Labels:  ['No' 'Yes']\n",
      "Confusion matrix:  [[145, 1], [0, 78]]\n",
      "Precision:  99.3151 %, Recall:  100.0 %, F1:  99.6564 %\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.427408218383789  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  99.55357142857143 % on  224  instances\n",
      "Labels:  ['No' 'Yes']\n",
      "Confusion matrix:  [[145, 1], [0, 78]]\n",
      "Precision:  99.3151 %, Recall:  100.0 %, F1:  99.6564 %\n",
      "Best value of hyperparmeter being tuned:  1\n",
      "[INFO]:  5 CPU cores will be allocated in parallel running\n",
      "CART  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  1.619767665863037  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "Accuracy:  97.16312056737588 % on  282  instances\n",
      "Labels:  ['Yes' 'No']\n",
      "Confusion matrix:  [[100, 3], [5, 174]]\n",
      "Precision:  97.0874 %, Recall:  95.2381 %, F1:  96.1539 %\n",
      "Normal Chef F1 Score:  0.6434782608695652\n",
      "Chef F1 Score after CV Tuning:  0.6434782608695652\n"
     ]
    }
   ],
   "source": [
    "# Run Chefboost Function\n",
    "chefTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best distance and NN parameters:  ('manhattan', 1)\n",
      "KNN F1 score after CV tuning:  0.5535714285714286\n"
     ]
    }
   ],
   "source": [
    "# Run KNN Function\n",
    "KNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "851fec3bcd0aee0b1bfa1b82c1ab8d3d9e4dc256454ac46a585b0f97f9328639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
